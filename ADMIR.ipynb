{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADMIR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSl7eGjNSLsAmpt9HPA2de",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajsrivathsa/image_registration/blob/main/ADMIR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uENFUaxrdBRN"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_QQG0blca17",
        "outputId": "8a753345-fb2f-47ea-c16f-122b673a29b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --upgrade nibabel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nibabel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/7f/d3c29792fae50ef4f1f8f87af8a94d5d9fe76550b86ebcf8a251110169d8/nibabel-3.2.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from nibabel) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->nibabel) (2.4.7)\n",
            "Installing collected packages: nibabel\n",
            "  Found existing installation: nibabel 3.0.2\n",
            "    Uninstalling nibabel-3.0.2:\n",
            "      Successfully uninstalled nibabel-3.0.2\n",
            "Successfully installed nibabel-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rT9Nd7ScgDi",
        "outputId": "a33cfae1-da37-42e9-f124-3cc2fa9dd152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-x6D4OnafOj",
        "outputId": "a2177990-e6ef-492d-d7e3-973e555f1a86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import nibabel as nb\n",
        "import os, sys, glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "\n",
        "print(\"nibabel version: {}\".format(nb.__version__))\n",
        "print(\"pytorch version: {}\".format(torch.__version__))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nibabel version: 3.2.0\n",
            "pytorch version: 1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O09OgvEJc_CM"
      },
      "source": [
        "t1_fn = '/content/drive/My Drive/Colab Notebooks/image_registration/T1_ixi/IXI002-Guys-0828-T1.nii.gz'\n",
        "t2_fn = '/content/drive/My Drive/Colab Notebooks/image_registration/T2_ixi/IXI002-Guys-0828-T2.nii.gz'  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWcFQJ_Sc-9p"
      },
      "source": [
        "data_path = \"/content/drive/My Drive/Colab Notebooks/image_registration/resampled_mri/admir_data\"\n",
        "file_names = glob.glob(os.path.join(data_path, \"*.nii.gz\"))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpv76iqJoJ3C",
        "outputId": "11757e5a-2a0d-4204-a582-db24cbbdb134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(file_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAVJGb_KdFbx"
      },
      "source": [
        "# Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aKmg-UYdJmK",
        "outputId": "a6151591-9a26-4bd9-9713-1c6c0ca3f2b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_nb1 = nb.load(file_names[0])\n",
        "img_nb1.shape\n",
        "img_nb2 = nb.load(file_names[1])\n",
        "img_nb2.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Q1VnK3rD-n"
      },
      "source": [
        "def load_4D(name):\n",
        "    X_nb = nb.load(name)\n",
        "    X_np = X_nb.dataobj\n",
        "    X_np = np.reshape(X_np, (1,)+ X_np.shape)\n",
        "    return X_np\n",
        "\n",
        "def imgnorm(N_I,index1=0.0001,index2=0.0001):\n",
        "    I_sort = np.sort(N_I.flatten())\n",
        "    I_min = I_sort[int(index1*len(I_sort))]\n",
        "    I_max = I_sort[-int(index2*len(I_sort))]\n",
        "    N_I =1.0*(N_I-I_min)/(I_max-I_min)\n",
        "    N_I[N_I>1.0]=1.0\n",
        "    N_I[N_I<0.0]=0.0\n",
        "    N_I2 = N_I.astype(np.float32)\n",
        "    return N_I2\n",
        "\n",
        "def Norm_Zscore(img):\n",
        "    img= (img-np.mean(img))/np.std(img) \n",
        "    return img"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBWv91cIdJpD"
      },
      "source": [
        "class Dataset(Data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, names,iterations,norm=True):\n",
        "        'Initialization'\n",
        "        self.names = names\n",
        "        self.norm = norm\n",
        "        self.iterations = iterations\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.names) * 2\n",
        "\n",
        "  def __getitem__(self, step):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        # print(self.names)\n",
        "        index_pair = np.random.permutation(len(self.names)) [0:4]\n",
        "        img_A = load_4D(self.names[index_pair[0]])\n",
        "        img_B = load_4D(self.names[index_pair[1]])     \n",
        "        \n",
        "        if self.norm:\n",
        "            return  Norm_Zscore(imgnorm(img_A)) , Norm_Zscore(imgnorm(img_B))\n",
        "        else:\n",
        "            return img_A, img_B\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDRNICPadJry"
      },
      "source": [
        "class Admir_Affine_Encoder(nn.Module):\n",
        "    def __init__(self, in_channel, start_channel, num_conv_blocks=6):\n",
        "        self.in_channel = in_channel\n",
        "        self.start_channel = start_channel\n",
        "        self.num_conv_blocks = num_conv_blocks\n",
        "        self.encoder_layer_list = []\n",
        "        super(Admir_Affine_Encoder, self).__init__()\n",
        "        self.create_model()\n",
        "\n",
        "    def affine_conv_block(self, in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, bias=True ):\n",
        "      layer = nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "                            nn.BatchNorm3d(out_channels),\n",
        "                            nn.LeakyReLU(negative_slope=0.1))\n",
        "      return layer\n",
        "    \n",
        "\n",
        "    def create_model(self):\n",
        "      for i in range(self.num_conv_blocks):\n",
        "          if(i == 0):\n",
        "            lyr = self.affine_conv_block(in_channels = self.in_channel, out_channels = self.start_channel)\n",
        "            self.encoder_layer_list.append(lyr)\n",
        "          else:\n",
        "            lyr = self.affine_conv_block(in_channels= self.start_channel * i, out_channels = self.start_channel * (i+1))\n",
        "            self.encoder_layer_list.append(lyr)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "      # print(\"x,y\", x.shape, \"  \", y.shape)\n",
        "      x_in=torch.cat((x, y), 1)\n",
        "      e0 = self.encoder_layer_list[0](x_in)\n",
        "      e1 = self.encoder_layer_list[1](e0)\n",
        "      e2 = self.encoder_layer_list[2](e1)\n",
        "      e3 = self.encoder_layer_list[3](e2)\n",
        "      e4 = self.encoder_layer_list[4](e3)\n",
        "      return e4\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtqnFkbuVzwY"
      },
      "source": [
        "affine_conv_model = Admir_Affine_Encoder(in_channel=2, start_channel=8, num_conv_blocks=5)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvm57AiccKZZ"
      },
      "source": [
        "training_generator = Data.DataLoader(Dataset(file_names,iterations=2,norm=True), batch_size=2, shuffle=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLm0ccWIWkHW",
        "outputId": "1131387b-912c-4430-ff44-922b14a0e65c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koh6nVdbk9yE",
        "outputId": "9399791b-8217-4fad-a867-bfd076a9f7bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ex1 = torch.rand(2, 40, 4, 4, 4)\n",
        "ex2 = ex1.flatten(start_dim=1, end_dim=4)\n",
        "ex2.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2560])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMnKqsEzdJua"
      },
      "source": [
        "class Admir_Affine_Output(nn.Module):\n",
        "  def __init__(self, in_units, out_units=128, dropout_prob = 0.3):\n",
        "    \n",
        "    self.in_units = in_units\n",
        "    self.out_units = out_units\n",
        "    self.dropout_prob = dropout_prob\n",
        "    super(Admir_Affine_Output, self).__init__()\n",
        "    self.trns_ob = self.translation_output_block(self.in_units, self.out_units)\n",
        "    self.rss_ob = self.rot_scale_shear_output_block(self.in_units, self.out_units)\n",
        "    return;\n",
        "  \n",
        "  def translation_output_block(self, in_units, out_units):\n",
        "    layer = nn.Sequential(\n",
        "          nn.Linear(in_features = in_units, out_features= out_units),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units, out_features= out_units//2),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units//2, out_features= out_units//4),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units//4, out_features= out_units//8),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units//8, out_features= 3))\n",
        "    return layer\n",
        "\n",
        "  def rot_scale_shear_output_block(self, in_units, out_units):\n",
        "    layer = nn.Sequential(\n",
        "          nn.Linear(in_features = in_units, out_features= out_units),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units, out_features= out_units//2),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units//2, out_features= out_units//4),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units//4, out_features= out_units//8),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(in_features=out_units//8, out_features= 9),\n",
        "          nn.Tanh())\n",
        "    return layer\n",
        "  \n",
        "  def forward(self, input_tnsr):\n",
        "    ip = input_tnsr.flatten(start_dim=1, end_dim=4)\n",
        "    #print(ip.shape)\n",
        "    translation_output = self.trns_ob(ip)\n",
        "    rotate_scale_shear_output = self.rss_ob(ip)\n",
        "    return [translation_output, rotate_scale_shear_output]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jyWklHIdJw-"
      },
      "source": [
        "affine_output_model = Admir_Affine_Output( in_units= 2560)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2igZOPlj4V",
        "outputId": "ab270e2b-0a93-464e-efcb-929231f0ed71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for X,Y in training_generator:\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  conv_out = affine_conv_model(X, Y)\n",
        "  print(conv_out.shape)\n",
        "  output_out = affine_output_model(conv_out)\n",
        "  print(output_out[0].shape)\n",
        "  print(output_out[1].shape)\n",
        "  print(\"========== ============== =============\")\n",
        "  print()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 9])\n",
            "========== ============== =============\n",
            "\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 9])\n",
            "========== ============== =============\n",
            "\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 9])\n",
            "========== ============== =============\n",
            "\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 9])\n",
            "========== ============== =============\n",
            "\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 1, 128, 128, 128])\n",
            "torch.Size([2, 40, 4, 4, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 9])\n",
            "========== ============== =============\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekf9ihEilj8O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBY7LjNtlkAS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}