{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FIRE_deformable_transformation_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajsrivathsa/image_registration/blob/main/FIRE_deformable_transformation_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdXND0_09Rn0"
      },
      "source": [
        "Reference Paper -\r\n",
        "\r\n",
        "https://arxiv.org/pdf/1907.05062.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6avvhUb1ux",
        "outputId": "af028f94-85d7-4f0c-d298-cbfc2396f383"
      },
      "source": [
        "!pip install SimpleITK"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 70kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o0NgdMOKRJb",
        "outputId": "a7251c2b-7614-4ad1-9201-cc6f7b38767d"
      },
      "source": [
        "import warnings\r\n",
        "import os\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "print(torch.__version__)\r\n",
        "import torchvision\r\n",
        "print(torchvision.__version__)\r\n",
        "import torch \r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.utils.data as Data\r\n",
        "# !pip install --upgrade nibabel\r\n",
        "import nibabel as nb\r\n",
        "import os, sys, glob\r\n",
        "import SimpleITK as sitk\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.0+cu101\n",
            "0.9.0+cu101\n",
            "Mounted at /content/drive\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvfubAXWp0GT"
      },
      "source": [
        "data_path_t1 = \"/content/drive/My Drive/Image_Registration_Project/dataset_ants_resampled/T1_Train_200_Reg_downsampled_znm/\"\r\n",
        "data_path_t2 = \"/content/drive/My Drive/Image_Registration_Project/dataset_ants_resampled/T1_Train_200_Reg_downsampled_znm/\"\r\n",
        "file_names_t1 = sorted(glob.glob(os.path.join(data_path_t1, \"*.nii.gz\")))\r\n",
        "file_names_t2 = sorted(glob.glob(os.path.join(data_path_t2, \"*.nii.gz\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypOa-6BWrGKt",
        "outputId": "fa1a1ef8-df26-4d05-b6e9-d4c694c760d0"
      },
      "source": [
        "img_nb1 = nb.load(file_names_t1[0])\r\n",
        "print(img_nb1.shape)\r\n",
        "img_nb2 = nb.load(file_names_t2[0])\r\n",
        "print(img_nb2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91, 109, 91)\n",
            "(91, 109, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNwHulnurnmY"
      },
      "source": [
        "def load_4D(name):\r\n",
        "        model_np = np.zeros(shape=(128, 128, 128))\r\n",
        "        resamplng_shape = (128, 128, 128)\r\n",
        "        X_nb = nb.load(name)\r\n",
        "        #print(X_nb)\r\n",
        "        X_np = X_nb.dataobj\r\n",
        "        #print(X_np)\r\n",
        "        x_dim, y_dim, z_dim = X_np.shape\r\n",
        "        #print(x_dim, y_dim, z_dim)\r\n",
        "        x_ltail = (resamplng_shape[0] - x_dim)//2 \r\n",
        "        y_ltail = (resamplng_shape[1] - y_dim)//2\r\n",
        "        z_ltail = (resamplng_shape[2] - z_dim)//2\r\n",
        "        #print(x_ltail,y_ltail,z_ltail)\r\n",
        "\r\n",
        "        x_rtail = resamplng_shape[0] - x_ltail - 1\r\n",
        "        y_rtail = resamplng_shape[1] - y_ltail - 1\r\n",
        "        z_rtail = resamplng_shape[2] - z_ltail - 1\r\n",
        "        #print(x_rtail,y_rtail,z_rtail)\r\n",
        "        model_np[x_ltail:x_rtail, y_ltail:y_rtail, z_ltail:z_rtail] = X_np[:, :, :]\r\n",
        "        #print(model_np)\r\n",
        "        return model_np\r\n",
        "\r\n",
        "def imgnorm(N_I,index1=0.0001,index2=0.0001):\r\n",
        "    I_sort = np.sort(N_I.flatten())\r\n",
        "    I_min = I_sort[int(index1*len(I_sort))]\r\n",
        "    I_max = I_sort[-int(index2*len(I_sort))]\r\n",
        "    N_I =1.0*(N_I-I_min)/(I_max-I_min)\r\n",
        "    N_I[N_I>1.0]=1.0\r\n",
        "    N_I[N_I<0.0]=0.0\r\n",
        "    N_I2 = N_I.astype(np.float32)\r\n",
        "    return N_I2\r\n",
        "\r\n",
        "def Norm_Zscore(img):\r\n",
        "    img= (img-np.mean(img))/np.std(img) \r\n",
        "    return img\r\n",
        "\r\n",
        "def save_img(I_img,savename):\r\n",
        "    I2 = sitk.GetImageFromArray(I_img,isVector=False)\r\n",
        "    sitk.WriteImage(I2,savename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fPbE6P0sAY9"
      },
      "source": [
        "class Dataset(Data.Dataset):\r\n",
        "  'Characterizes a dataset for PyTorch'\r\n",
        "  def __init__(self, names_t1,names_t2,iterations =1,norm=True):\r\n",
        "        'Initialization'\r\n",
        "        self.names_t1 = names_t1\r\n",
        "        self.names_t2 = names_t2\r\n",
        "        self.norm = norm\r\n",
        "        self.iterations = iterations\r\n",
        "  def __len__(self):\r\n",
        "        'Denotes the total number of samples'\r\n",
        "        return len(self.names_t1) * self.iterations\r\n",
        "\r\n",
        "  def __getitem__(self, step):\r\n",
        "        'Generates one sample of data'\r\n",
        "        # index_pair = np.random.permutation(len(self.names)) [0:4]\r\n",
        "        img_A = load_4D(self.names_t1[step])\r\n",
        "        img_B = load_4D(self.names_t2[step])     \r\n",
        "        \r\n",
        "        if self.norm:\r\n",
        "            # return  Norm_Zscore(imgnorm(img_A)) , Norm_Zscore(imgnorm(img_B))\r\n",
        "            return  imgnorm(img_A) , imgnorm(img_B)\r\n",
        "        else:\r\n",
        "            return img_A, img_B\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RESGorrI8bjQ"
      },
      "source": [
        "training_generator = Data.DataLoader(Dataset(file_names_t1,file_names_t2,True), batch_size=2,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvB1_YjTYEaU",
        "outputId": "ec00298f-90df-44da-d403-bf425b1779c6"
      },
      "source": [
        "for  X,Y in training_generator:\r\n",
        "  print(torch.max(X))\r\n",
        "  print(torch.min(Y))\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Ml3SHDbn2G",
        "outputId": "498fd25e-e192-40cb-b8d7-daf909a7465b"
      },
      "source": [
        "sitk_t1 = sitk.ReadImage(file_names_t1[0])\r\n",
        "print(sitk_t1.GetSize())\r\n",
        "print(load_4D(file_names_t1[0]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91, 109, 91)\n",
            "(128, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syo473VzaIcZ"
      },
      "source": [
        "# Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9pH8t_5aMwl"
      },
      "source": [
        "def conv3x3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv3d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
        "    \n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na9OSfx-aM7D",
        "outputId": "125c92ed-415c-4dec-e99a-d3b46a85e2d6"
      },
      "source": [
        "ResidualBlock(in_channels = 2, out_channels = 512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResidualBlock(\n",
              "  (conv1): Conv3d(2, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "  (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "  (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93_Cl9JQYthk"
      },
      "source": [
        "# Transformation deformable network\n",
        " ### Please uncomment cdb variables as they are intended to be used for fullsized images Xa and not Ga, Gb ######\n",
        "  ### Once commented take care of the same in the forward layer ########  \n",
        "\n",
        "  In actual code it is better to hardcode number of channels instead of using start channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDRKYLXpYzBr"
      },
      "source": [
        "class Transformation_Deformable_Network(nn.Module):\n",
        "  def __init__(self,start_channel):\n",
        "        # self.in_channel = in_channel\n",
        "        self.start_channel = start_channel\n",
        "\n",
        "        ## Declarations ##### \n",
        "        ### Please uncomment cdb variables as they are intended to be used for fullsized images Xa and not Ga, Gb ######\n",
        "        ### Once commented take care of the same in the forward layer ########     \n",
        "        super(Transformation_Deformable_Network, self).__init__()\n",
        "        self.cdb_1_1 = self.convdownsampleblock(1, 16)\n",
        "        self.cdb_1_2 = self.convdownsampleblock(1, 16)\n",
        "        self.cdb_2_1 = self.convdownsampleblock(16, 64)\n",
        "        self.cdb_2_2 = self.convdownsampleblock(16, 64)\n",
        "\n",
        "        #self.convblock1 = self.convblock(self.start_channel * 32, self.start_channel * 16)\n",
        "        #self.convblock2 = self.convblock(self.start_channel * 16, self.start_channel * 4)\n",
        "        self.convblock1 = self.convblock(self.start_channel * 32, 8)\n",
        "        self.convblock2 = self.convblock(self.start_channel * 32, 8)\n",
        "\n",
        "        self.rb1 = ResidualBlock(16, 16, 1)\n",
        "\n",
        "        ## Harcoded to get the output channels to 3 as deformable field has 3 fields ##\n",
        "        self.convblock3 = self.convblock(16, 3)\n",
        "        self.lkrelublock1 = self.leakyrelublock()\n",
        "        self.lkrelublock2 = self.leakyrelublock()\n",
        "        self.lkrelublock3 = self.leakyrelublock()\n",
        "\n",
        "        #self.inb1 = self.instancenormblock(self.start_channel * 3)\n",
        "        #self.inb2 = self.instancenormblock(self.start_channel * 3)\n",
        "\n",
        "        self.inb1 = self.instancenormblock(3)\n",
        "        self.inb2 = self.instancenormblock(3)\n",
        "\n",
        "\n",
        "        self.tb1 = self.tanhblock()\n",
        "\n",
        "        return;\n",
        "\n",
        "\n",
        "  def convblock(self, in_channels, out_channels, kernel_size=3, bias=False, batchnorm=False):\n",
        "    layer = nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias, padding=1),)\n",
        "    return layer\n",
        "\n",
        "  def convdownsampleblock(self, in_channels , out_channels, kernel_size=3, stride=2, padding=1, bias=True):\n",
        "    layer = nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "                                      nn.BatchNorm3d(out_channels),\n",
        "                                      nn.ReLU())\n",
        "    return layer\n",
        "          \n",
        "  def leakyrelublock(self):\n",
        "    layer = nn.LeakyReLU()\n",
        "    return layer\n",
        "          \n",
        "  def instancenormblock(self, out_channels):\n",
        "    layer = nn.InstanceNorm3d(out_channels)\n",
        "    return layer\n",
        "\n",
        "  def tanhblock(self):\n",
        "    layer = nn.Tanh()\n",
        "    return layer\n",
        "\n",
        "  def forward(self, gx, gy):\n",
        "    cdb11 = self.cdb_1_1(gx)\n",
        "    cdb12 = self.cdb_1_2(gy)\n",
        "    cdb21 = self.cdb_2_1(cdb11)\n",
        "    cdb22 = self.cdb_2_2(cdb12)\n",
        "\n",
        "    cb1 = self.convblock1(cdb21)\n",
        "    cb1 = self.lkrelublock1(cb1)\n",
        "    cb2 = self.convblock2(cdb22)\n",
        "    cb2 = self.lkrelublock2(cb2)\n",
        "\n",
        "    cat_in=torch.cat((cb1, cb2), 1)\n",
        "\n",
        "    rb = self.rb1(cat_in)\n",
        "    print(rb.shape)\n",
        "    ib1 = self.inb1(rb)\n",
        "    print(ib1.shape)\n",
        "    lk = self.lkrelublock3(ib1)\n",
        "    cb3 = self.convblock3(lk)\n",
        "    ib2 = self.inb2(cb3)\n",
        "    tanhb1 = self.tb1(ib2)\n",
        "    return tanhb1;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3C3G5U_YzKe"
      },
      "source": [
        "mymodel = Transformation_Deformable_Network(2).to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--oDjiHMYzM6"
      },
      "source": [
        "x = torch.randn(size=(2, 1, 128, 128, 128)).to(\"cuda\")\n",
        "y = torch.randn(size=(2, 1, 128, 128, 128)).to(\"cuda\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T74ErL8SYzVF",
        "outputId": "f990979a-328b-4f1a-f442-35db8d393ad5"
      },
      "source": [
        "tanhbo = mymodel(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 16, 32, 32, 32])\n",
            "torch.Size([2, 16, 32, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIrsJlXPYzdi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMS-PEnJYzmu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SpbDW_erJMP"
      },
      "source": [
        "# Spatial Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6vVCkvPrL9_"
      },
      "source": [
        "class SpatialTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    N-D Spatial Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, is_affine=False, theta = None, mode='bilinear', affine_image_size =  (2, 1, 128, 128, 128)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mode = mode\n",
        "        self.isaffine = is_affine\n",
        "        self.theta = theta\n",
        "        self.affine_image_size =  affine_image_size\n",
        "        # create sampling grid\n",
        "        # registering the grid as a buffer cleanly moves it to the GPU, but it also\n",
        "        # adds it to the state dict. this is annoying since everything in the state dict\n",
        "        # is included when saving weights to disk, so the model files are way bigger\n",
        "        # than they need to be. so far, there does not appear to be an elegant solution.\n",
        "        # see: https://discuss.pytorch.org/t/how-to-register-buffer-without-polluting-state-dict\n",
        "\n",
        "        if (self.isaffine):\n",
        "          grid = F.affine_grid(self.theta, self.affine_image_size, align_corners=False)\n",
        "          #grid = grid.permute(0, 4, 1, 2, 3)\n",
        "          self.register_buffer('grid', grid)\n",
        "        else:\n",
        "          vectors = [torch.arange(0, s) for s in size]\n",
        "          grids = torch.meshgrid(vectors)\n",
        "          grid = torch.stack(grids)\n",
        "          grid = torch.unsqueeze(grid, 0)\n",
        "          grid = grid.type(torch.FloatTensor)\n",
        "          self.register_buffer('grid', grid)\n",
        "\n",
        "    def forward(self, src, flow=None):      \n",
        "      if (self.isaffine):\n",
        "        grid = F.affine_grid(self.theta, self.affine_image_size)        \n",
        "        warped_image = F.grid_sample(src, grid)\n",
        "        #warped_image = warped_image.permute(0, 4, 1, 2, 3)\n",
        "        return warped_image\n",
        "      else:\n",
        "        # new locations\n",
        "        print(self.grid.shape)\n",
        "        print(flow.shape)\n",
        "        new_locs = self.grid + flow\n",
        "        shape = flow.shape[2:]\n",
        "\n",
        "        # need to normalize grid values to [-1, 1] for resampler\n",
        "        for i in range(len(shape)):\n",
        "            new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5)\n",
        "\n",
        "        # move channels dim to last position\n",
        "        # also not sure why, but the channels need to be reversed\n",
        "        if len(shape) == 2:\n",
        "            new_locs = new_locs.permute(0, 2, 3, 1)\n",
        "            new_locs = new_locs[..., [1, 0]]\n",
        "        elif len(shape) == 3:\n",
        "            new_locs = new_locs.permute(0, 2, 3, 4, 1)\n",
        "            new_locs = new_locs[..., [2, 1, 0]]\n",
        "\n",
        "        return F.grid_sample(src, new_locs, align_corners=True, mode=self.mode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkb7wUZrMKK",
        "outputId": "c1ad09bf-9de2-452c-a433-302728caea87"
      },
      "source": [
        "spatial_transformer_deformable = SpatialTransformer(size=(32, 32, 32), is_affine=False).to(\"cuda\")\n",
        "print(spatial_transformer_deformable.grid.shape)\n",
        "print(spatial_transformer_deformable.isaffine)\n",
        "print(\"========= =========== ======\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 32, 32, 32])\n",
            "False\n",
            "========= =========== ======\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEtyvuMCrMMy"
      },
      "source": [
        "gx_affine = torch.randn(size=(2, 128, 32, 32, 32)).to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZgMgorb5Npv"
      },
      "source": [
        "# Output of deformable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCcUHjlq5SWq",
        "outputId": "ffa49e50-5876-442c-b879-cfefb46c481c"
      },
      "source": [
        "stdef_op = spatial_transformer_deformable(gx_affine, tanhbo)\n",
        "print(stdef_op.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 32, 32, 32])\n",
            "torch.Size([2, 3, 32, 32, 32])\n",
            "torch.Size([2, 128, 32, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0crpHjw5SfZ",
        "outputId": "b8dec7f9-91a3-4c3e-8c93-0264c8847829"
      },
      "source": [
        "stdef_op = spatial_transformer_deformable(x, tanhbo)\n",
        "print(stdef_op.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 32, 32, 32])\n",
            "torch.Size([2, 3, 32, 32, 32])\n",
            "torch.Size([2, 1, 32, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO3dcrwnA4cx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}